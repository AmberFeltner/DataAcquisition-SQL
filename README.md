In the course of my work, I first address the fundamental aspects of framing a relevant research question and providing a detailed description of all variables within the selected dataset, ensuring alignment with real-world organizational needs.

Moving on to the data-cleaning phase, I meticulously devise a plan that encompasses a range of techniques and specific steps aimed at assessing and enhancing the quality of the dataset. The chosen approach is carefully justified, taking into account the unique characteristics of the data, and the entire process is executed using Python as the programming language, supported by relevant libraries. The annotated code for this data quality assessment is thoughtfully provided in an executable script file.

The subsequent data-cleaning process is summarized, encompassing the identification and mitigation of data quality issues. I provide a detailed account of the findings, the rationale behind the methods employed for issue resolution, and the outcomes of each data-cleaning step. The annotated code for mitigating these data quality issues is encapsulated in an executable script file, and the cleaned dataset is made accessible in CSV format.

To enrich the understanding of the data set, I incorporate principal component analysis (PCA) as a sophisticated technique. The application of PCA involves identifying the total number of principal components, presenting the output of the principal components loading matrix, and justifying the reduced number of principal components through the inclusion of a scree plot screenshot. In parallel, I delve into the organizational benefits derived from the implementation of PCA, emphasizing its contribution to informed decision-making processes.

Throughout this comprehensive process, I address not only the technical aspects of data cleaning and analysis but also the strategic implications and organizational advantages that stem from these efforts. The limitations of the data-cleaning process are candidly acknowledged, and their potential impact on the subsequent analysis is thoroughly discussed, providing a holistic perspective on the entire workflow.
